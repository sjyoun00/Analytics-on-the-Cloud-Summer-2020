{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.graphx._\n",
       "import org.apache.spark.rdd.RDD\n",
       "v: org.apache.spark.rdd.RDD[(Long, Int)] = ParallelCollectionRDD[30] at parallelize at <console>:36\n",
       "e: org.apache.spark.rdd.RDD[org.apache.spark.graphx.Edge[Int]] = ParallelCollectionRDD[31] at parallelize at <console>:37\n",
       "g: org.apache.spark.graphx.Graph[Int,Int] = org.apache.spark.graphx.impl.GraphImpl@5d2ea\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.graphx._\n",
    "import org.apache.spark.rdd.RDD\n",
    "\n",
    "\n",
    "val v = sc.parallelize(Array((1L,1),(2L,2),(3L,3),(4L,4),(5L,5)))\n",
    "val e = sc.parallelize(Array(Edge(1,2,3),Edge(2,3,1),Edge(3,4,1)))\n",
    "\n",
    "val g: Graph[Int,Int] = Graph(v,e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res4: Array[(org.apache.spark.graphx.VertexId, Int)] = Array((4,4), (1,1), (5,5), (2,2), (3,3))\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.vertices.collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res5: Array[org.apache.spark.graphx.Edge[Int]] = Array(Edge(1,2,3), Edge(2,3,1), Edge(3,4,1))\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.edges.collect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a subgraph\n",
    "\n",
    "#### Criterion 1\n",
    "<li>choose edges with value greater than 1</li>\n",
    "<li>all vertices are selected (no vertex condition)</li>\n",
    "<li>only edge with attr > 1 is selected (two edges are dropped)</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "verts: Array[(org.apache.spark.graphx.VertexId, Int)] = Array((4,4), (1,1), (5,5), (2,2), (3,3))\n",
       "edgs: Array[org.apache.spark.graphx.Edge[Int]] = Array(Edge(1,2,3))\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// choose all vertices\n",
    "val verts = g.subgraph(e=>e.attr>1,(v_id,v_attr) => true).vertices.collect\n",
    "// choose edges with attribute value greater than 1 ==> one edge left: (1,2,3)\n",
    "val edgs = g.subgraph(e=>e.attr>1,(v_id,v_attr) => true).edges.collect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Criterion 2\n",
    "<li>choose vertices with attr greater than 2</li>\n",
    "<li>vertices 3,4,5 are included</li>\n",
    "<li>even though all three edges satisfy the edge criterion, <b>only Edge(3,4,1) survives</b> becasue the other two edges each have at least one vertices that are not in the vertex set</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "verts: Array[(org.apache.spark.graphx.VertexId, Int)] = Array((4,4), (5,5), (3,3))\n",
       "edgs: Array[org.apache.spark.graphx.Edge[Int]] = Array(Edge(3,4,1))\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// choose vertices with attribute value greater than 2 ==> only 3,4,5 are included\n",
    "val verts = g.subgraph(e=>true,(v_id,v_attr) => v_attr>2).vertices.collect\n",
    "// edge.selector chooses all edges, but only 1 edge(3,4,1) is included, \n",
    "// because the other two edges each have at least one vertices that are not in the vertex set\n",
    "// Edge(1,2,3), Edge(2,3,1) are filtered out, here\n",
    "val edgs = g.subgraph(e=>true,(v_id,v_attr) => v_attr>2).edges.collect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Combining the two</li>\n",
    "<li>None of the edges survive because either their vertices are not in the final set or they don't satsify the edge condition</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "verts: Array[(org.apache.spark.graphx.VertexId, Int)] = Array((4,4), (5,5), (3,3))\n",
       "edgs: Array[org.apache.spark.graphx.Edge[Int]] = Array()\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Edge(3,4,1) is also gone, since the edge attribute value is not greater than 1\n",
    "val verts = g.subgraph(e=>e.attr>1,(v_id,v_attr) => v_attr>2).vertices.collect\n",
    "val edgs = g.subgraph(e=>e.attr>1,(v_id,v_attr) => v_attr>2).edges.collect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Bottom line</h3>\n",
    "<li>Edges in the subgraph must satisfy the <b>edge condition</b> AND <b>both vertices in the edge must satisfy the vertex condition</b></li>\n",
    "<li>Vertices in the subgraph must satisfy the <b>vertex condition</b></li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
