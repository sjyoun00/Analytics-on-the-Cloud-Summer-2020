{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook was ran on a cluster on Google Cloud due to the very large size of dataset `nyc_data.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>PROBLEM 1</h1>\n",
    "\n",
    "Write an Apache Spark program that <b>uses <span style=\"color:green\">map</span> and <span style=\"color:green\">reduceByKey</span> to compute the average processing time by borough for 311 complaints.</b> You can read the data from the file nyc_data.csv. Each row represents a NYC 311 processing case, column 6 contains the borough and column 7 the processing time for each case. <b>You must use reduceByKey!</b>\n",
    "\n",
    "You need to run your program on a cluster on the cloud. \n",
    "\n",
    "NOTES:\n",
    "\n",
    "1. The Spark function <span style=\"color:blue\">contains</span> works somewhat like the python in function. See the example below\n",
    "\n",
    "2. Only include data rows where the borough is either of BRONX, MANHATTAN, QUEENS, STATEN ISLAND, BROOKLYN\n",
    "\n",
    "3. You also need to account for any missing data in the processing times (you can ignore missing data in borough because you'll be filtering boroughs anyway)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "result = MapPartitionsRDD[297] at mapValues at <console>:51\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[(STATEN ISLAND,4.7309033311163775), (BROOKLYN,6.19202093132757), (MANHATTAN,6.720885143835739), (QUEENS,5.064014618641129), (BRONX,5.959183187781855)]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// PROBLEM 1 SOLUTION HERE\n",
    "val result = sc.textFile(\"gs://zhangzy_cloud_analytics/data/nyc_data.csv\")       // read data from Bucket\n",
    "    .mapPartitionsWithIndex{ (idx,iter) => if (idx==0) iter.drop(1) else iter}   // remove header\n",
    "    .map(l=>l.split(\",\")).map(l=>(l(6),l(7)))                                    // extract only Boroughs and Times\n",
    "    .filter(l=>(l._1.contains(\"BRONX\")||l._1.contains(\"MANHATTAN\")||             // filter Boroughs\n",
    "                l._1.contains(\"QUEENS\")||l._1.contains(\"STATEN ISLAND\")||\n",
    "                l._1.contains(\"BROOKLYN\")))\n",
    "    .filter(l=>try {\n",
    "            l._2.toDouble\n",
    "            true\n",
    "        } catch {\n",
    "            case e: Exception => false\n",
    "        }\n",
    "    )                                                                            // filter missing Time values\n",
    "    .map(l=>(l._1,l._2.toDouble))                                                // convert Time values into Double\n",
    "    .map(l=>{if (l._1.contains(\"BRONX\")) (\"BRONX\",l._2)                          //\n",
    "           else if (l._1.contains(\"MANHATTAN\")) (\"MANHATTAN\",l._2)               // convert Strings containing\n",
    "           else if (l._1.contains(\"QUEENS\")) (\"QUEENS\",l._2)                     // a Borough into Strings==\"Borough\" \n",
    "           else if (l._1.contains(\"STATEN ISLAND\")) (\"STATEN ISLAND\",l._2)       // i.e. \"05 BRONX\" ==> \"BRONX\"\n",
    "           else (\"BROOKLYN\",l._2)})                                              \n",
    "    .mapValues(value=>(value,1.0))                                                      // count each entry\n",
    "    .reduceByKey{case ((timeA,countA),(timeB,countB)) => (timeA+timeB,countA+countB)}   // sum up the Times and Counts\n",
    "    .mapValues{case (sum , count) => sum/count}                                         // calculate the average time\n",
    "                                                                                        // by Borough\n",
    "result.collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Some(http://cluster-ieor4526-m.c.ieor-4526-cloud-analytics.internal:4041)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Run the cell below and make sure the result (Out[[n]]:  ) is visible when you submit the file\n",
    "//This returns the url of the master and will confirm that you ran the code on the cluster\n",
    "//For example, my return value is:\n",
    "// Some(http://cluster-01cb-m.c.cloud-class-spring2020.internal:4040)\n",
    "\n",
    "sc.uiWebUrl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step by step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "raw_data = gs://zhangzy_cloud_analytics/data/nyc_data.csv MapPartitionsRDD[273] at textFile at <console>:27\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "gs://zhangzy_cloud_analytics/data/nyc_data.csv MapPartitionsRDD[273] at textFile at <console>:27"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val raw_data = sc.textFile(\"gs://zhangzy_cloud_analytics/data/nyc_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.partitions.length   // default partition number = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "raw_data_header_removed = MapPartitionsRDD[274] at mapPartitionsWithIndex at <console>:31\n",
       "r1 = 1521028\n",
       "r2 = 1521027\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1521027"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val raw_data_header_removed = raw_data.mapPartitionsWithIndex{ (idx,iter) => if (idx==0) iter.drop(1) else iter}\n",
    "val r1 = raw_data.count\n",
    "val r2 = raw_data_header_removed.count    // only 1 row is dropped: the header row in the first partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "record number,Unique Key,Created Date,Closed Date,Agency,Descriptor,Borough,processing_time"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.first()    // header that was removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,32305299,2016-01-01 00:00:09,2016-01-01 01:57:32,NYPD,Loud Music/Party,BROOKLYN,0.0815162037037037\n",
      "5,323056566,2016-01-01 00:00:09,2016-01-01 01:57:32,NYPD,Loud Music/Party,BROOKLYN,NaN5,323056566,2016-01-01 00:00:09,2016-01-01 01:57:32,NYPD,Loud Music/Party,BROOKLYN,NaN5,323056566,2016-01-01 00:00:09,2016-01-01 01:57:32,NYPD,Loud Music/Party,BROOKLYN,NaN\n",
      "1,32310343,2016-01-01 00:00:40,2016-01-01 03:12:53,NYPD,Loud Music/Party,BRONX,0.1334837962962963\n",
      "2,32309107,2016-01-01 00:01:09,2016-01-21 09:20:55,HPD,NO LIGHTING,07 BRONX,20.388726851851853\n",
      "3,32308578,2016-01-01 00:02:59,2016-01-01 23:35:50,NYPD,Loud Music/Party,Unspecified,0.9811458333333334\n"
     ]
    }
   ],
   "source": [
    "raw_data_header_removed.take(5).foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "borough_time_map = MapPartitionsRDD[280] at map at <console>:45\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[280] at map at <console>:45"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val borough_time_map = raw_data_header_removed         // filter missing Time values and Borough values\n",
    "    .map(l=>l.split(\",\"))\n",
    "    .map(l=>(l(6),l(7)))\n",
    "    .filter(l=>(l._1.contains(\"BRONX\")||l._1.contains(\"MANHATTAN\")||\n",
    "                l._1.contains(\"QUEENS\")||l._1.contains(\"STATEN ISLAND\")||\n",
    "                l._1.contains(\"BROOKLYN\")))\n",
    "    .filter(l=>try {\n",
    "            l._2.toDouble\n",
    "            true\n",
    "        } catch {\n",
    "            case e: Exception => false\n",
    "        }\n",
    "    )\n",
    "    .map(l=>(l._1,l._2.toDouble))\n",
    "    .map(l=>{if (l._1.contains(\"BRONX\")) (\"BRONX\",l._2)\n",
    "           else if (l._1.contains(\"MANHATTAN\")) (\"MANHATTAN\",l._2)\n",
    "           else if (l._1.contains(\"QUEENS\")) (\"QUEENS\",l._2)\n",
    "           else if (l._1.contains(\"STATEN ISLAND\")) (\"STATEN ISLAND\",l._2)\n",
    "           else (\"BROOKLYN\",l._2)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(BROOKLYN,0.0815162037037037)\n",
      "(BRONX,0.1334837962962963)\n",
      "(BRONX,20.388726851851853)\n",
      "(BRONX,7.048576388888889)\n",
      "(QUEENS,0.1400810185185185)\n",
      "(BROOKLYN,0.11086805555555555)\n",
      "(MANHATTAN,0.016967592592592593)\n",
      "(MANHATTAN,0.1597222222222222)\n",
      "(BRONX,2.996585648148148)\n",
      "(BROOKLYN,0.06299768518518518)\n"
     ]
    }
   ],
   "source": [
    "borough_time_map.take(10).foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map(STATEN ISLAND -> 64361, QUEENS -> 318541, MANHATTAN -> 315748, BROOKLYN -> 429754, BRONX -> 275485)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "borough_time_map.countByKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count_by_borough = MapPartitionsRDD[283] at mapValues at <console>:33\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[283] at mapValues at <console>:33"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val count_by_borough = borough_time_map.mapValues(value=>(value,1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(BROOKLYN,(0.0815162037037037,1.0))\n",
      "(BRONX,(0.1334837962962963,1.0))\n",
      "(BRONX,(20.388726851851853,1.0))\n",
      "(BRONX,(7.048576388888889,1.0))\n",
      "(QUEENS,(0.1400810185185185,1.0))\n",
      "(BROOKLYN,(0.11086805555555555,1.0))\n",
      "(MANHATTAN,(0.016967592592592593,1.0))\n",
      "(MANHATTAN,(0.1597222222222222,1.0))\n",
      "(BRONX,(2.996585648148148,1.0))\n",
      "(BROOKLYN,(0.06299768518518518,1.0))\n"
     ]
    }
   ],
   "source": [
    "count_by_borough.take(10).foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sum_by_borough = ShuffledRDD[284] at reduceByKey at <console>:35\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ShuffledRDD[284] at reduceByKey at <console>:35"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val sum_by_borough = count_by_borough.reduceByKey{case ((timeA,countA),(timeB,countB)) => (timeA+timeB,countA+countB)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "averagetime_by_borough = MapPartitionsRDD[285] at mapValues at <console>:37\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[285] at mapValues at <console>:37"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val averagetime_by_borough = sum_by_borough.mapValues{case (sum , count) => sum/count}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(STATEN ISLAND,4.7309033311163775), (BROOKLYN,6.19202093132757), (MANHATTAN,6.720885143835739), (QUEENS,5.064014618641129), (BRONX,5.959183187781855)]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "averagetime_by_borough.collect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>PROBLEM 1</h1>\n",
    "\n",
    "Write an Apache Spark program that <b>uses <span style=\"color:green\">map</span> and <span style=\"color:green\">reduceByKey</span> to compute the average processing time by borough for 311 complaints.</b> You can read the data from the file nyc_data.csv. Each row represents a NYC 311 processing case, column 6 contains the borough and column 7 the processing time for each case. <b>You must use reduceByKey!</b>\n",
    "\n",
    "You need to run your program on a cluster on the cloud. \n",
    "\n",
    "NOTES:\n",
    "\n",
    "1. The Spark function <span style=\"color:blue\">contains</span> works somewhat like the python in function. See the example below\n",
    "\n",
    "2. Only include data rows where the borough is either of BRONX, MANHATTAN, QUEENS, STATEN ISLAND, BROOKLYN\n",
    "\n",
    "3. You also need to account for any missing data in the processing times (you can ignore missing data in borough because you'll be filtering boroughs anyway)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true\n",
      "false\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "y: Array[Int] = Array(5, 7, 9)\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val y = Array(5,7,9)\n",
    "println(y.contains(7))\n",
    "println(y.contains(11))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
