{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Initialize PySpark</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Assignment 8 ML Basics\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Mody necessary imports</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.feature import QuantileDiscretizer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Read the data and split into training and testing sets</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format('csv').options(header='false').load('cal_housing.data')\n",
    "train,test = df.randomSplit((0.8,0.2),seed=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Write the prepareData function</h1>\n",
    "<li>Same as what we did in the class so it's done for you</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "def prepareData(df):\n",
    "    df = df.toDF(\"Longitude\",\"Latitude\",\"MedianAge\",\"TotalRooms\",\"TotalBedrooms\",\"Population\",\"Households\",\n",
    "            \"MedianIncome\",\"MedianHomeValue\")\n",
    "    df = df.select(*(col(c).cast(\"float\").alias(c) for c in df.schema.names))\n",
    "    df = df.withColumn(\"MedianHomeValue\",col(\"MedianHomeValue\")/100000)\n",
    "    df = df.withColumn(\"RoomsPerHouse\", col(\"TotalRooms\")/col(\"Households\"))\\\n",
    "        .withColumn(\"PeoplePerHouse\", col(\"Population\")/col(\"Households\"))\\\n",
    "       .withColumn(\"BedroomsPerHouse\", col(\"TotalBedrooms\")/col(\"Households\"))\n",
    "    df_analysis = df.select(\"MedianHomeValue\", \n",
    "              \"MedianAge\", \n",
    "              \"Population\", \n",
    "              \"Households\", \n",
    "              \"MedianIncome\", \n",
    "              \"RoomsPerHouse\", \n",
    "              \"PeoplePerHouse\", \n",
    "              \"BedroomsPerHouse\")\n",
    "    return df_analysis\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Transform the dependent variable into two buckets</h1>\n",
    "<li>Use QuantileDiscretizer with two buckets</li>\n",
    "<li><a href=\"https://spark.apache.org/docs/latest/ml-features#quantilediscretizer\">https://spark.apache.org/docs/latest/ml-features#quantilediscretizer</a></li>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "discretizer = QuantileDiscretizer(numBuckets=2, inputCol=\"MedianHomeValue\", outputCol=\"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Transform independent variable features into a vector</h1>\n",
    "<li>Same as class, so done for you</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler()\\\n",
    "    .setInputCols((\"MedianAge\",\"Population\", \"Households\", \n",
    "                        \"MedianIncome\", \"RoomsPerHouse\", \"PeoplePerHouse\", \"BedroomsPerHouse\"))\\\n",
    "    .setOutputCol(\"features\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Build two models</h1>\n",
    "<li>A Logistic Regression Model</li>\n",
    "<li>A Random Forest Classifier</li>\n",
    "<li><a href=\"https://spark.apache.org/docs/latest/ml-classification-regression.html\">https://spark.apache.org/docs/latest/ml-classification-regression.html</a></li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8,labelCol=\"label\", featuresCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", numTrees=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Create pipelines</h1>\n",
    "<li>Create p1 with two stages: the bucketizer that uses QuantileDiscretizer and the assembler</li>\n",
    "<li>Create p2 with two stages: p1 and logistic regression</li>\n",
    "<li>Create p3 with two stages: p1 and random forest classifier</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = Pipeline().\\\n",
    "    setStages((discretizer,assembler))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2 = Pipeline().\\\n",
    "    setStages((p1,lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "p3 = Pipeline().\\\n",
    "    setStages((p1,rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Run the two pipelines with training data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = p2.fit(prepareData(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = p3.fit(prepareData(train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Get predictions for both models</h1>\n",
    "<li>On training as well as testing data sets</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_training_predictions = lr_model.transform(prepareData(train))\n",
    "lr_testing_predictions = lr_model.transform(prepareData(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- MedianHomeValue: double (nullable = true)\n",
      " |-- MedianAge: float (nullable = true)\n",
      " |-- Population: float (nullable = true)\n",
      " |-- Households: float (nullable = true)\n",
      " |-- MedianIncome: float (nullable = true)\n",
      " |-- RoomsPerHouse: double (nullable = true)\n",
      " |-- PeoplePerHouse: double (nullable = true)\n",
      " |-- BedroomsPerHouse: double (nullable = true)\n",
      " |-- label: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_training_predictions.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|label|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|  0.0|[19.0,1431.0,608....|[0.09115704430670...|[0.52277349336246...|       0.0|\n",
      "|  0.0|[17.0,333.0,117.0...|[0.07747723998945...|[0.51935962676014...|       0.0|\n",
      "|  0.0|[27.0,117.0,34.0,...|[0.06174127728250...|[0.51543041792146...|       0.0|\n",
      "|  0.0|[20.0,624.0,262.0...|[0.06750215798802...|[0.51686913457431...|       0.0|\n",
      "|  0.0|[14.0,515.0,226.0...|[0.02140424061302...|[0.50535085586738...|       0.0|\n",
      "|  0.0|[25.0,1841.0,633....|[0.04014254935353...|[0.51003428991637...|       0.0|\n",
      "|  0.0|[29.0,671.0,239.0...|[0.01586899387397...|[0.50396716521623...|       0.0|\n",
      "|  0.0|[34.0,3134.0,1056...|[0.05828766765427...|[0.51456779269881...|       0.0|\n",
      "|  0.0|[41.0,375.0,158.0...|[0.07538833192058...|[0.51883816175685...|       0.0|\n",
      "|  0.0|[21.0,1182.0,437....|[0.07841979649255...|[0.51959490830958...|       0.0|\n",
      "|  0.0|[46.0,787.0,271.0...|[0.05782912876328...|[0.51445325452436...|       0.0|\n",
      "|  0.0|[16.0,1115.0,242....|[0.05837137043737...|[0.51458870060562...|       0.0|\n",
      "|  0.0|[31.0,1346.0,479....|[0.02066548351086...|[0.50516618702208...|       0.0|\n",
      "|  0.0|[48.0,580.0,211.0...|[0.05905554329484...|[0.51475959649494...|       0.0|\n",
      "|  1.0|[26.0,5.0,3.0,0.5...|[0.11805083007731...|[0.52947848112916...|       0.0|\n",
      "|  0.0|[15.0,949.0,300.0...|[0.10631436716654...|[0.52655358580183...|       0.0|\n",
      "|  0.0|[10.0,1152.0,481....|[0.07546475506908...|[0.51885724039573...|       0.0|\n",
      "|  0.0|[21.0,64.0,27.0,0...|[0.10636531593220...|[0.52656628705245...|       0.0|\n",
      "|  0.0|[28.0,666.0,256.0...|[0.02964341608795...|[0.50741031139004...|       0.0|\n",
      "|  0.0|[17.0,1005.0,401....|[0.07572313871472...|[0.51892174411243...|       0.0|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_training_predictions.select(\"label\",\"features\",\"rawPrediction\",\"probability\",\"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- MedianHomeValue: double (nullable = true)\n",
      " |-- MedianAge: float (nullable = true)\n",
      " |-- Population: float (nullable = true)\n",
      " |-- Households: float (nullable = true)\n",
      " |-- MedianIncome: float (nullable = true)\n",
      " |-- RoomsPerHouse: double (nullable = true)\n",
      " |-- PeoplePerHouse: double (nullable = true)\n",
      " |-- BedroomsPerHouse: double (nullable = true)\n",
      " |-- label: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_testing_predictions.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|label|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|  0.0|[15.0,1015.0,472....|[0.08320172252195...|[0.52078843963663...|       0.0|\n",
      "|  0.0|[19.0,1129.0,463....|[0.07132332842781...|[0.51782327713772...|       0.0|\n",
      "|  0.0|[17.0,83.0,45.0,1...|[0.07876916255589...|[0.51968211508478...|       0.0|\n",
      "|  0.0|[16.0,2434.0,824....|[0.04003701634317...|[0.51000791726168...|       0.0|\n",
      "|  0.0|[20.0,1135.0,303....|[0.07789210974938...|[0.51946318787569...|       0.0|\n",
      "|  0.0|[24.0,227.0,139.0...|[0.10493510633797...|[0.52620973056278...|       0.0|\n",
      "|  0.0|[18.0,3424.0,283....|[0.07841979649255...|[0.51959490830958...|       0.0|\n",
      "|  0.0|[32.0,623.0,169.0...|[0.07349229946248...|[0.51836480973411...|       0.0|\n",
      "|  0.0|[19.0,649.0,173.0...|[0.01680063092517...|[0.50420005893895...|       0.0|\n",
      "|  0.0|[15.0,2097.0,622....|[0.05269420119152...|[0.51317050291750...|       0.0|\n",
      "|  0.0|[21.0,805.0,239.0...|[0.04231152472647...|[0.51057630336310...|       0.0|\n",
      "|  0.0|[24.0,1416.0,401....|[0.06568254867841...|[0.51641473622646...|       0.0|\n",
      "|  0.0|[23.0,1148.0,388....|[0.08161502681342...|[0.52039243843569...|       0.0|\n",
      "|  0.0|[34.0,1013.0,274....|[0.04416023955966...|[0.51103826611337...|       0.0|\n",
      "|  0.0|[15.0,653.0,185.0...|[-0.0255561702992...|[0.49361130513561...|       1.0|\n",
      "|  0.0|[34.0,1627.0,522....|[0.02080012638307...|[0.50519984412312...|       0.0|\n",
      "|  0.0|[21.0,1164.0,421....|[-0.0013772327164...|[0.49965569187531...|       1.0|\n",
      "|  0.0|[15.0,803.0,277.0...|[-0.0190055924024...|[0.49524874491626...|       1.0|\n",
      "|  0.0|[16.0,961.0,327.0...|[0.09442141814146...|[0.52358783255033...|       0.0|\n",
      "|  0.0|[18.0,1161.0,343....|[0.05825127815781...|[0.51455870304248...|       0.0|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_testing_predictions.select(\"label\",\"features\",\"rawPrediction\",\"probability\",\"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_training_predictions = rf_model.transform(prepareData(train))\n",
    "rf_testing_predictions = rf_model.transform(prepareData(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- MedianHomeValue: double (nullable = true)\n",
      " |-- MedianAge: float (nullable = true)\n",
      " |-- Population: float (nullable = true)\n",
      " |-- Households: float (nullable = true)\n",
      " |-- MedianIncome: float (nullable = true)\n",
      " |-- RoomsPerHouse: double (nullable = true)\n",
      " |-- PeoplePerHouse: double (nullable = true)\n",
      " |-- BedroomsPerHouse: double (nullable = true)\n",
      " |-- label: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_training_predictions.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|label|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|  0.0|[19.0,1431.0,608....|[8.08651947434545...|[0.80865194743454...|       0.0|\n",
      "|  0.0|[17.0,333.0,117.0...|[8.45449075178655...|[0.84544907517865...|       0.0|\n",
      "|  0.0|[27.0,117.0,34.0,...|[8.46597719490942...|[0.84659771949094...|       0.0|\n",
      "|  0.0|[20.0,624.0,262.0...|[8.38972095370328...|[0.83897209537032...|       0.0|\n",
      "|  0.0|[14.0,515.0,226.0...|[6.56939150065826...|[0.65693915006582...|       0.0|\n",
      "|  0.0|[25.0,1841.0,633....|[6.70123655003746...|[0.67012365500374...|       0.0|\n",
      "|  0.0|[29.0,671.0,239.0...|[6.52567347987796...|[0.65256734798779...|       0.0|\n",
      "|  0.0|[34.0,3134.0,1056...|[8.01534226754972...|[0.80153422675497...|       0.0|\n",
      "|  0.0|[41.0,375.0,158.0...|[8.35896499978746...|[0.83589649997874...|       0.0|\n",
      "|  0.0|[21.0,1182.0,437....|[8.36715706912335...|[0.83671570691233...|       0.0|\n",
      "|  0.0|[46.0,787.0,271.0...|[8.38972095370328...|[0.83897209537032...|       0.0|\n",
      "|  0.0|[16.0,1115.0,242....|[8.59739278594908...|[0.85973927859490...|       0.0|\n",
      "|  0.0|[31.0,1346.0,479....|[6.32313110699660...|[0.63231311069966...|       0.0|\n",
      "|  0.0|[48.0,580.0,211.0...|[8.45238214080776...|[0.84523821408077...|       0.0|\n",
      "|  1.0|[26.0,5.0,3.0,0.5...|[7.99987200526693...|[0.79998720052669...|       0.0|\n",
      "|  0.0|[15.0,949.0,300.0...|[8.38972095370328...|[0.83897209537032...|       0.0|\n",
      "|  0.0|[10.0,1152.0,481....|[8.38875075273308...|[0.83887507527330...|       0.0|\n",
      "|  0.0|[21.0,64.0,27.0,0...|[7.95582064234788...|[0.79558206423478...|       0.0|\n",
      "|  0.0|[28.0,666.0,256.0...|[7.82098121029190...|[0.78209812102919...|       0.0|\n",
      "|  0.0|[17.0,1005.0,401....|[8.61532576260426...|[0.86153257626042...|       0.0|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_training_predictions.select(\"label\",\"features\",\"rawPrediction\",\"probability\",\"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- MedianHomeValue: double (nullable = true)\n",
      " |-- MedianAge: float (nullable = true)\n",
      " |-- Population: float (nullable = true)\n",
      " |-- Households: float (nullable = true)\n",
      " |-- MedianIncome: float (nullable = true)\n",
      " |-- RoomsPerHouse: double (nullable = true)\n",
      " |-- PeoplePerHouse: double (nullable = true)\n",
      " |-- BedroomsPerHouse: double (nullable = true)\n",
      " |-- label: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_testing_predictions.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|label|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|  0.0|[15.0,1015.0,472....|[8.61532576260426...|[0.86153257626042...|       0.0|\n",
      "|  0.0|[19.0,1129.0,463....|[8.61532576260426...|[0.86153257626042...|       0.0|\n",
      "|  0.0|[17.0,83.0,45.0,1...|[8.57743437358305...|[0.85774343735830...|       0.0|\n",
      "|  0.0|[16.0,2434.0,824....|[6.75082007322346...|[0.67508200732234...|       0.0|\n",
      "|  0.0|[20.0,1135.0,303....|[8.62814873986489...|[0.86281487398648...|       0.0|\n",
      "|  0.0|[24.0,227.0,139.0...|[8.14929542178839...|[0.81492954217883...|       0.0|\n",
      "|  0.0|[18.0,3424.0,283....|[8.69080992696938...|[0.86908099269693...|       0.0|\n",
      "|  0.0|[32.0,623.0,169.0...|[8.60323615245231...|[0.86032361524523...|       0.0|\n",
      "|  0.0|[19.0,649.0,173.0...|[7.74383107977677...|[0.77438310797767...|       0.0|\n",
      "|  0.0|[15.0,2097.0,622....|[8.28723440051512...|[0.82872344005151...|       0.0|\n",
      "|  0.0|[21.0,805.0,239.0...|[8.36908737920774...|[0.83690873792077...|       0.0|\n",
      "|  0.0|[24.0,1416.0,401....|[8.35799479881726...|[0.83579947988172...|       0.0|\n",
      "|  0.0|[23.0,1148.0,388....|[8.19119426334203...|[0.81911942633420...|       0.0|\n",
      "|  0.0|[34.0,1013.0,274....|[8.60323615245231...|[0.86032361524523...|       0.0|\n",
      "|  0.0|[15.0,653.0,185.0...|[5.10008068500990...|[0.51000806850099...|       0.0|\n",
      "|  0.0|[34.0,1627.0,522....|[6.07364609793551...|[0.60736460979355...|       0.0|\n",
      "|  0.0|[21.0,1164.0,421....|[5.84858827133337...|[0.58485882713333...|       0.0|\n",
      "|  0.0|[15.0,803.0,277.0...|[4.29815210196691...|[0.42981521019669...|       1.0|\n",
      "|  0.0|[16.0,961.0,327.0...|[8.35896499978746...|[0.83589649997874...|       0.0|\n",
      "|  0.0|[18.0,1161.0,343....|[8.46597719490942...|[0.84659771949094...|       0.0|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_testing_predictions.select(\"label\",\"features\",\"rawPrediction\",\"probability\",\"prediction\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Print testing stats for each model</h1>\n",
    "<li>Accuracy</li>\n",
    "<li>Area under ROC</li>\n",
    "<li>Area under Precision-Recall curve</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7412937432595157"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_evaluator = BinaryClassificationEvaluator()\\\n",
    "  .setLabelCol(\"label\")\\\n",
    "  .setRawPredictionCol(\"prediction\")\n",
    "lr_test_accuracy = lr_evaluator.evaluate(lr_testing_predictions)\n",
    "lr_test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7962028358567652"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "rf_test_accuracy = rf_evaluator.evaluate(rf_testing_predictions)\n",
    "rf_test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Print training stats for each model</h1>\n",
    "<li>Accuracy</li>\n",
    "<li>Area under ROC</li>\n",
    "<li>Area under Precision-Recall curve</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7447346580520845"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_train_accuracy = lr_evaluator.evaluate(lr_training_predictions)\n",
    "lr_train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_train_sum = lr_model.stages[1].summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "areaUnderROC: 0.8305139145196938\n"
     ]
    }
   ],
   "source": [
    "print(\"areaUnderROC: \" + str(lr_train_sum.areaUnderROC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8052066266156926"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_train_accuracy = rf_evaluator.evaluate(rf_training_predictions)\n",
    "rf_train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_train_sum = rf_model.stages[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Coefficients in the logistic regression</h1>\n",
    "<li>Notice how this is different from the linear regression coefficients</li>\n",
    "<li>Still dominated by income but some other flavors have crept in</li>\n",
    "<li>Print this out nicely formatted. Each line should contain the feature and it's coefficient</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients:  (7,[3],[0.036392134132822884])\n",
      "Intercept:  -0.13755701445839436\n"
     ]
    }
   ],
   "source": [
    "# Print the coefficients and intercept for logistic regression\n",
    "lrModel = lr_model.stages[1]\n",
    "print(\"Coefficients: \",lrModel.coefficients)\n",
    "print(\"Intercept: \",lrModel.intercept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Draw Training ROC and Precision-Recall Curves (LR Model only)</h1>\n",
    "<li>include the area under roc and area under pr curves in your plots</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "\n",
    "# Compute raw scores on the test set\n",
    "predictionAndLabels = lr_training_predictions.select(\"rawPrediction\")\n",
    "\n",
    "# Instantiate metrics object\n",
    "metrics = BinaryClassificationMetrics(predictionAndLabels)\n",
    "\n",
    "# Area under precision-recall curve\n",
    "print(\"Area under PR = %s\" % metrics.areaUnderPR)\n",
    "\n",
    "# Area under ROC curve\n",
    "print(\"Area under ROC = %s\" % metrics.areaUnderROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>https://spark.apache.org/docs/latest/mllib-evaluation-metrics.html#binary-classification</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Draw testing ROC</h1>\n",
    "<li>For this, the easiest is to use sklearn's roc and pr functionalities</li>\n",
    "<li>The predictions contain two useful columns, the probability and the dependent value bucket</li>\n",
    "<li>Extract these into a data frame</li>\n",
    "<li>Note that the probability is expressed as a pair (probability of 0 and probability of 1)</li>\n",
    "<li>Extract the probability of 1 from this (convert the df into an rdd, it will be easier!)</li>\n",
    "<li>Also convert all values to float from Spark DoubleType (sklearn won't understand DoubleType)</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
